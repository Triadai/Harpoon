% -*- latex -*- This is a LaTeX document.
% $Id: pldi99-results.tex,v 1.1 1999-11-11 19:56:13 cananian Exp $
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental results}\label{sec:sptc_results}
The full SPTC analysis and optimization has been implemented in the
FLEX java compiler platform.\footnote{See
section~\ref{sec:methodology} for details of methodology.}
Some quantitative measure of the utility
of SPTC is given as Figure~\ref{fig:sptc_numbers}.  The ``run-times''
given are intermediate representation dynamic statement counts
generated by the FLEX compiler SSI IR interpreter.  The FLEX
infrastructure is still under development, and its backends are not
stable enough to allow directly executable code.  As such, the numbers
bear a tenuous relation to reality; in particular branch delays on
real architectures, which the elimination of null-pointer checks seeks
to eliminate, are unrepresented.  Furthermore, the intermediate
representation interpreter gives the same cycle-count to two-operand
instructions as to loading constants, which tends to negate most of
the benefit of constant propagation.  As is obvious from the figure,
the standard Wegman-Zadeck SCC algorithm, which has proven utility in
practice, shows no improvement over unoptimized code due to the metric
used.  Even so, SPTC shows a 10\% speed-up.  It is expected that the
improvement given in actual practice will be greater.
\begin{myfigure}
\centering
\includegraphics[scale=0.33,angle=-90,clip=true,trim=1cm 0 0 0]%
{Figures/THscccomp.eps}
\caption{SPTC optimization performance.}
\label{fig:sptc_numbers}
\end{myfigure}

Note that the speed-up is constant despite widely differing test
cases.  The ``Hello world'' example actually executes quite a bit of
library code in the Java implementation; this includes numerous
element-by-element array initializations (due to the semantics of
java bytecode) which we expect SPTC to excel at optimizing.  But SPTC
does just as well on the full FLEX compiler (68,032 lines of source
at the time the benchmark was run), which shows that the speed-up is
not limited to constant initialization code.

\section{Bit-width analysis}\label{sec:bitwidth}
The SPTC algorithm can be extended to allow efficient
\newterm{bit-width analysis}.  Bit-width analysis is a variation of
constant propagation with the goal of determining value ranges for
variables.  In this sense it is similar to, but simpler than,
array-bounds analysis: no symbolic manipulation is required and the
value lattice has $N$ levels (where $N$ is the maximum bitwidth of the
underlying datatype) instead of $2^N$.  For C and Java programs, this
means that only 32 levels need be added to the lattice; thus the
bit-width analysis can be made efficient.

Bit-width analysis allows optimization for modern media-processing
instruction set extensions which typically offer vector processing of
limited-width types. Intel's MMX extensions, for example, offer packed
8-bit, 16-bit, 32-bit and 64-bit vectors \cite{peleg97:mmx}.
To take advantage of these functional units without explicit human
annotation, the compiler must be able to guarantee that the data in a
vector can be expressed using the limited bit-width available.  A
simpler bit-width analysis in a previous work \cite{ananian:siliconc}
showed that a large amount of width-limit information can be extracted
from appropriate source programs; however, that work was not able to
intelligently compute widths of loop-bound variables due to the
limitations of the SSA form.  Extending the bitwidth algorithm to SSI
form allows induction variables width-limited by loop-bounds to be
detected.

Bit-width analysis is also a vital step in compiling a high-level
language to a hardware description.  General purpose programming
languages do not contain the fine-grained bit-width information that a
hardware implementation can take advantage of, so the compiler must
extract it itself.  The work cited showed that this is viable
and efficient.

\begin{myfigure}
\begin{eqnarray*}
-\tuple{M,P} &=& \tuple{P,M}\\
\tuple{M_l,P_l} + \tuple{M_r,P_r} &=& \tuple{1+\max(M_l,M_r),1+\max(P_l,P_r)}\\
\tuple{M_l,P_l} \times \tuple{M_r,P_r} &=& \tuple{\max(M_l+P_r,P_l+M_r),
                                             \max(M_l+M_r,P_l+P_r)}\\
\tuple{0,P_l} \wedge \tuple{0,P_r} &=& \tuple{0,\min(P_l,P_r)}\\
\tuple{M_l,P_l}\wedge \tuple{M_r,P_r} &=& \tuple{\max(M_l,M_r),\max(P_l,P_r)}
\end{eqnarray*}%
\caption{Some combination rules for bit-width analysis.}\label{fig:bitrules}
\end{myfigure}
The bit-width analysis algorithm has been implemented in the FLEX
compiler infrastructure.  Because most types in Java are signed, it is
necessary to separate bit-width information into ``positive width''
and ``negative width.''  This is just an extension of the
signed value lattice of Figure~\ref{fig:scclat6} to variable
bit-widths.  In practice the bit-widths are represented by a tuple,
extending the integer constant lattice with
$(\domain{Int}\times\domain{Int})_{\bot}$ under the natural total
ordering of \domain{Int}.  The tuple $\tuple{0,0}$ is identical to the
constant 0, and the tuple $\tuple{0,16}$ represents an ordinary
unsigned 16-bit data type.  The $\top$ element is represented by an
appropriate tuple reflecting the source-language semantics of the
value's type.  Figure~\ref{fig:bitrules} presents bit-width
combination rules for some unary negation and binary addition,
multiplication and bitwise-and.  In practice, the rules would be
extended to more precisely handle operands of zero, one, and other
small constants.
