\index{Lock(s)!problems with}
Atomicity in shared-memory multiprocessors is 
conventionally provided
via mutual-exclusion \defn{locks} (see, for example,
\cite{Tanenbaum92}[p.~35]).  Although locks are easy to
implement using test-and-set, compare-and-swap, or
load-linked/{\bp}store-conditional instructions, they introduce a host of
difficulties.  Protocols to avoid deadlock when locking multiple
objects often involve acquiring the locks in a consistent linear
order, which may make programming with locks error-prone and introduce
significant overheads.  The granularity of each lock must also be
explicitly chosen: locks which are too fine introduce unnecessary
space and time overhead, while locks which are too coarse sacrifice
attainable parallelism (or may even deadlock).  Every access to a
shared object must hold some lock protecting that object, regardless
of whether another thread is actually attempting to access the same object.

\defn{Transactions} are
an alternative means of providing concurrency control.
A transaction can be thought of as a sequence of loads and stores
performed as part of a program which either
\defn{commits} or \defn{aborts}.  If a transaction
commits, then all of the loads and stores appear to have run
atomically with respect to other transactions.  That is, the
transaction's operations are not interleaved with those of other
transactions.  If a transaction aborts, then none of its stores take
effect and the transaction may be restarted, with some mechanism to
ensure forward progress.

This thesis will provide efficient implementations of
transaction primitives to enable their general use.
By structuring concurrency at a high level with transactions, human
programmers no longer have to manage the details required to ensure
atomicity.  Programmers have difficulty correctly understanding the global
interactions between multiple threads, each holding its own set of
locks, and a full mental model of the global concurrency structure
must be kept in mind when writing synchronization code.
The simpler ``global atomicity'' guaranteed under the
transactional model eliminates errors and simplifies the conceptual
model of the system, making future modifications safer as
well.  Previously, implementations of transactions were too slow for
general use.

The transaction primitives presented in this thesis can exploit
optimistic concurrency, provide fault tolerance, and prevent delays by
using non-blocking synchronization.
Although transactions can be implemented using mutual exclusion
(locks), our algorithms will utilize non-blocking synchronization
\index{Non-blocking synchronization}\index{Synchronization!non-blocking}
\cite{Lamport77,Herlihy88,HerlihyLuMo03,MassalinPu91,GreenwaldCh96} to
exploit optimistic concurrency among transactions.  Non-blocking
synchronization offers a number of advantages; foremost for the
concerns of this thesis is fault tolerance.  A process that fails
while holding a lock within a critical region can prevent all other
non-failing processes from ever making progress.  It is in general not
possible to restore the locked data structures to a consistent state
after such a failure.  Non-blocking synchronization offers a graceful
solution to this trouble, as non-progress or failure of any one thread
will not affect the progress or consistency of other threads or the
system.

Implementing transactions using
non-blocking synchronization offers performance benefits as well.
When mutual exclusion is used to enforce atomicity, page
page faults, cache misses, context
switches, I/O, and other unpredictable events may result in delays to the
entire system. Non-blocking
synchronization allows undelayed processes or processors to continue
to make progress.
Similarly, in real-time systems, the use of non-blocking
synchronization can prevent \defnlti{Priority inversion}
\index{Lock(s)!priority inversion} in the system
\cite{Jones97}, although na\"{\i}ve implementations may result in
starvation of low-priority tasks (see \charef{progress} for a discussion).

In this thesis I will show how transactions can be integrated into an
object-oriented language and used for backtracking, exception
handling, and concurrency control in new programs, in addition to
expressing atomicity and fault-tolerance.

One of the common synchronization mistakes made in lock-based
object-oriented code is
the ``multiple object problem'': when lock A protects object A, and
lock B protects object B, it is easy to get into trouble when writing
routines which involve both objects A and B.  Either insufficient
locks are taken, or both locks are taken without carefully considering
deadlock, or else one object's locks are released and reacquired during the
operation allowing atomicity to be broken.
In \charef{safe-transactify} I will describe a technique
for ``transactifying'' existing lock-based code
to identify or fix some existing concurrency bugs.

Previous implementation work has concentrated on the
\defni{Transactional memory} abstraction
\cite{Knight86,HerlihyMo93,StoneStHe93,RajwarGo02,ShavitTo95,HerlihyLuMoSc03},
which has
been proposed as a general and flexible way to allow programs to read
and modify disparate primary memory locations atomically as a single
operation, much as a database transaction can atomically modify many
records on disk.

\index{HTM|see{Hardware Transactional Memory}}
\index{STM|see{Software Transactional Memory}}
\index{Hardware Transactional Memory}
\defn{Hardware transactional memory} (HTM) supports atomicity through
architectural means, whereas \defn{software transactional memory}
\index{Software Transactional Memory}
(STM) supports atomicity through languages, compilers, and libraries.
I will present both software and hardware implementations of the
transaction model.

Researchers of both HTM and STM commonly express the opinion that
transactions need never touch many memory locations, and hence it is
reasonable to put a (small) bound on their
size~\cite{HerlihyMo93,HerlihyLuMoSc03}.\footnote{%
For example, \cite[section 5.2]{HerlihyMo93} states,
``Our [HTM] implementation relies on the assumption that transactions have
short durations and small data sets''; while 
the STM described in \cite{HerlihyLuMoSc03} has quadratic slowdown when
transactions touch many objects: performance is $O((R+W)R)$, where $R$
and $W$ are the number of objects opened for reading and writing,
respectively.}
For HTM implementations,
they conclude that a small piece of additional hardware---typically in
the form of a fixed-size content-addressable memory and supporting
logic---should suffice.  For STM implementations, some researchers
argue additionally that transactions occur infrequently, and hence the
software overhead would be dwarfed by the other processing done by an
application.
In contrast, this thesis will assume that transactions may be of
arbitrary size and duration, and that details of the implementation
should not be exposed to the programmer of the system.

My goal is to
make concurrent and fault-tolerant programming easier,
without incurring excessive overhead.  I support
unbounded transactions because neither programmers nor compilers can
easily cope when an architecture imposes a hard limit on transaction
size.  An implementation might be optimized for transactions below a
certain size, but must still operate correctly for larger
transactions.  The size of transactional hardware should be an
implementation parameter, like cache size or memory size, which can
vary without affecting the portability of binaries.

In \charef{hybrid} I will show how a fast hardware implementation for
frequent short transactions can gracefully fail over to a software
implementation designed to efficiently execute large long-lived
transactions.
The hybrid approach allows more sophisticated transaction models to be
implemented, while allowing a simpler hardware transaction mechanism
to provide speed in the common case.


%%%%%%%%%%%%% LIST OF CONTRIBUTIONS %%%%%%%%%%%%%%%%%%%
\section{Contributions}
This thesis makes the following contributions:

\begin{itemize}
\item We provide efficient implementations of
transaction primitives to enable their general use.
%%%%%%% MORE ACCURACY FOR THE ABOVE CLAIM?
\item The transaction
primitives presented in this thesis can exploit optimistic
concurrency, provide fault tolerance, and prevent delays by using
non-blocking synchronization.
\item 
I will show how transactions can be integrated into an
object-oriented language and used for backtracking, exception
handling, and concurrency control in new programs, in addition to
expressing atomicity and fault-tolerance.
\punt{
\item In \charef{safe-transactify} I will describe a technique
for ``transactifying'' existing lock-based code
to identify or fix existing concurrency bugs.
}
\item I will present both software and hardware implementations of the
transaction model.
\item Unlike some previous work, this thesis will assume that transactions may be of
arbitrary size and duration, and that details of the implementation
should not be exposed to the programmer of the system.
\item In \charef{hybrid} I will show how a fast hardware implementation for
frequent short transactions can gracefully fail over to a software
implementation designed to efficiently execute large long-lived
transactions.
\end{itemize}
%%%%%%%%%%%%% END LIST OF CONTRIBUTIONS %%%%%%%%%%%%%%%%%%%


\section{Motivation}
I will motivate the transactional programming model by
presenting four different common scenarios which are needlessly
difficult using lock-based concurrency; I will then present four novel
applications which a transactional model facilitates.  To ground the
discussion in reality, I conclude by enumerating a few cases where
transactions may \emph{not} be the best solution.

\subsection{Four old things you can't (easily) do with locks}
Locks engender fragile and complex safety protocols which
are often expressed external to their implementations, poor modularity
and composability, and an inability to deal gracefully with
asynchronous events.  These limitations of locks are well-known
\cite{Herlihy05}.

\subsubsection{Tweak performance with localized changes}
% global lock orders, oh my!
Preventing deadlocks and races requires global protocols and non-local
reasoning.  It is not enough to simply specify a lock of a certain
granularity protecting certain data items; the order or circumstances
in which the lock may be acquired and released must also be specified
globally, in the context of all locks in the system, in order to
prevent deadlocks or unexpected races.  This prevents the programmer
from easily tuning the system using localized changes: every small
change must be re-verified against the protocols specified in the
whole-program context in order to prevent races and/or deadlock.

% usage rules embedded in comments
Furthermore, this whole-program protocol is not typically expressed
directly in code: with common programming languages acquire/release
ordering and guarantees must be expressed externally, often as
comments in the source code which easily drift out of sync with the
implementation.  For example, in \cite{AnanianAsKuLeLi04} we counted
the comments in the Linux filesystem layer, and found that about 15\%
of these relate to locking protocols; often describing global
invariants of the program which are difficult to verify.  Many
reported kernel bugs involve races and deadlocks.

% races, lost wakeups ?

\subsubsection{Atomically move data between two thread-safe containers}
% locks don't compose
Another common programming pitfall with locks is their
\defn{non-composability}.\index{Lock(s)!non-composability}
For example, given two thread-safe
container classes implemented with locks, it is impossible to
safely compose
the \textit{get} function of one with the \textit{put} function of
the another to create an atomic move.  We must peek inside the
implementation of the containers to synthesize an appropriate locking
mechanism for such an action; for example, to acquire the appropriate
locks on \emph{both} containers (which may be at container, element,
or some other level) before attempting the operation -- and even then,
we need to resort to some global lock ordering to guard against
deadlock.  Modularity must be broken in order to synthesize the
appropriate composed function, which may be impossible.

In the Java programming language, Martin Rinard presented a partial
solution using ``implicitly synchronized'' objects.  Lock acquistion
for each module is exposed in the module's API as an executable
``access declaration.''  Operation composition is accomplished by
creating an access declaration for the composed operation which
invokes the appropriate access declarations for the components.  The
runtime system orders the lock acquisitions to prevent deadlock.  This
process suffices for conservative mutual exclusion, but it is limited in its
ability to express alternative operation orders which preserve
atomicity of the composed operation while overlapping its components
\cite[p14]{Rinard98}.

Transactions do not suffer from the composability problem
\cite{HarrisMaPeHe05}.  Because transactions only specify the atomicity
properties, not the locks required, the programmer's job is eased and
implementations are free to order operations in any way which
preserves atomicity.

\subsubsection{Create a thread-safe double-ended queue}
% publishable result: michael/scott, 1996 PPoPP
Herlihy suggests creating a thread-safe double-ended queue using locks
as ``sadistic homework'' for computer science students \cite{Herlihy05}.
Although double-ended queues are a simple data structure,
creating a scalable locking protocol is a
non-trivial exercise: one wants dequeue and enqueue operations to
complete concurrently when the ends of the queue are ``far enough''
apart, while safely handling the interference in the small-queue case.
In fact, the solution to this assignment was a publishable result, as
Michael and Scott demonstrated in 1996 \cite{MichaelSc96}.

The simple ``one lock'' solution to the double-ended queue
problem, ruled out as unscalable in the locking case, is scalable and
efficient for non-blocking transactions.

\subsubsection{Handle asynchronous exceptions}
Properly handling asynchronous events is difficult with locks, because
it is impossible to safely go off to handle the event while holding an
arbitrary set of locks---and it is impossible to safely drop the
locks.  The solution implemented in the Real-Time Specification for
Java and similar systems is to generally forbid asynchronous events within
locked regions, allowing the programmer to explicitly specify certain
points within the region at which execution can be interrupted,
dropping all locks in order to do so.  Maintaining the correctness
in the face of even explicitly-declared interruption points is still
difficult.

Transactional atomic regions handle asynchronous exceptions
gracefully: the transaction is aborted to allow an
event to occur.

\subsection{Four new things transactions make easy}

I present three examples in this section, illustrating how
transactions can support fault tolerance and backtracking,
simplify locking, and provide a more intuitive
means for specifying thread-safety properties.
I will first examine a destructive traversal algorithm, showing how a
transaction implementation can be treated as an exception-handling
mechanism.   I then, using a network flow example, show how this
transaction mechanism can be used to simplify
the locking discipline required when synchronizing concurrent
modifications to multiple objects.
Finally, I show an existing race in the Java standard libraries (in 
the class \texttt{java.lang.StringBuffer}).  ``Transactification'' of
the existing class corrects this race.

\subsubsection{Destructive traversal}\label{sec:destruct}
Many recursive data structures can be traversed without the use of a
stack using pointer reversal.  This technique is widely used in
garbage collectors, and was first demonstrated in this context by
Schorr and Waite \cite{SchorrWa67}.  The following code implements a
pointer-reversal traversal of a simple singly-linked list:
\begin{inlinecode}
// destructive list traversal.
void traverse(List l) {
  List last = null, t;
  
  /* zip through the list, reversing links */
  for (int i=0; i<2; i++) {
    do {
      if (i==0) visit(l); // visit node
      t = l.next;
      l.next = last;
      last = l;
      l = t;
    } while (l!=null);
    l = last;
    // now do again, backwards. (restoring links)
  }
}
\end{inlinecode}

This function traverses the list, visiting nodes in order and then
reversing the {\tt next} pointer.  When the end of the list is
reached, the reversed links are traversed to restore the list's original
state.  

Of course, I have chosen the simplest possible data structure here, but
the technique works for trees and graphs---and the reader may mentally
substitute their favorite hairy update on a complicated data
structure.

In normal execution, the data structure is left complete and intact
after the operation.  But
imagine that an exception or fault occurs inside the {\tt visit()} method
at some point during the traversal: an assertion fires, an exception
occurs, the hardware hiccups, or a thread is killed.  Control may
leave the {\tt traverse()} method, but the data structure is left in
shambles.  What is needed is some exception-handling procedure to
restore the proper state of the list.  This can be manually coded with
Java's existing {\tt try}/{\tt catch} construct, but the
exception-handling code must be tightly-coupled to the traversal if it
is going to undo the list mutations.

\note{Used to have a try/catch with explicit fail in here.}
Instead, I can provide a non-deterministic choice operator,
{\tt try}/{\tt else}, and write the recovery code at a higher-level as:
\begin{inlinecode}
try {
  traverse(list);
} else { // try-else construct
  throw new Error();
}
\end{inlinecode}
\note{I'd prefer `fail t' here, but that raises the question of how
  to export objects from transactional contexts.}

The {\tt try}/{\tt else} block appears to make a non-deterministic
choice between executing the {\tt try} or the {\tt else} clause,
depending on whether the {\tt try} would succeed or not.
This can be straight-forwardly implemented
with a transaction around the traversal,
always initially attempting
the {\tt try}.  Exceptions or faults cause the transaction to abort;
when it does so all the
heap side-effects of the {\tt try} block disappear.

Introducing an explicit {\tt fail} statement allows us to use the same
{\tt try}/{\tt else} for backtracking search.\index{Backtracking}
\note{Insert example here?}

\subsubsection{Network flow}\label{sec:flow}\index{Network flow}

Let's now turn our attention now to parallel codes.
Consider a serial program for computing network flow (see, for
example, \cite[Chapter 26]{CormenLeRi01}).  The inner loop of the code
pushes flow across an edge by increasing the ``excess flow'' on one
vertex and decreasing it by the same amount on another vertex.  One
might see the following Java code:
\begin{inlinecode}
void pushFlow(Vertex v1, Vertex v2, double flow) {
  v1.excess += flow; /* Move excess flow from v1 */
  v2.excess -= flow; /* to v2.                   */
}
\end{inlinecode}

To parallelize this code, one must preclude multiple threads from
modifying the excess flow on those two vertices at the same time.
Locks provide one way to enforce this mutual exclusion: 
\begin{inlinecode}
void pushFlow(Vertex v1, Vertex v2, double f) {
  Object lock1, lock2;
  if (v1.id < v2.id) {       /* Avoid deadlock. */
    lock1 = v1; lock2 = v2;
  } else {
    lock1 = v2; lock2 = v1;
  }
  synchronized(lock1) {
    synchronized(lock2) {
      v1.excess += f; /* Move excess flow from v1 */
      v2.excess -= f; /* to v2.                   */
    } /* unlock lock2 */
  } /* unlock lock1 */
}
\end{inlinecode}

This code is surprisingly complicated and slow compared to the
original.  Space for each object's lock must be reserved.
To avoid deadlock, the code must acquire the locks in
a consistent linear order, resulting in an unpredictable branch in the
code.  In the code shown,
I have required the programmer to insert an \texttt{id} field into
each vertex object to maintain a total ordering.
The time required to acquire the locks may be
an order of magnitude larger than the time to
modify the excess flow.
\note{Using FLEX, the locking code is over 11x
  slower than the no-locks code.  With Sun's JVM, this overhead falls
  to about 1.7x, because Sun is wicked smart about their lock
  implementations.}
What's more, all of this overhead is rarely
needed!  For a graph with thousands or millions of vertices, the
number of threads operating on the graph is likely to be less than a
hundred.  Consequently, the chances are quite small that two different
threads actually conflict.  Without the locks to implement mutual
exclusion, however, the program would occasionally fail.

Software transactions (and some language support) allow the
programmer to parallelize the original code using an \texttt{atomic}
keyword to indicate that the code block should appear to execute
atomically: 
\begin{inlinecode}
void pushFlow(Vertex v1, Vertex v2, double flow) {
  atomic { /* Transaction begin. */
    v1.excess += flow; /* Move excess flow from v1 */
    v2.excess -= flow; /* to v2.                   */
  } /* Transaction end. */
}
\end{inlinecode}

This {\tt atomic} region can be implemented as a transaction, and
with an appropriately non-blocking implementation, it
will scale better and execute faster than the locking version
\cite{AnanianAsKuLeLi04,HarrisFr03,GreenwaldCh96,MassalinPu91,HerlihyMo93,ShavitTo95}.
From the programmer's point of view, I have also eliminated the
convoluted locking protocol, which must
be observed rigorously everywhere the related fields are accessed if
deadlock and races are to be avoided.

Further, I can implement {\tt atomic} using the {\tt try}/{\tt else}
exception-handling mechanism I have already introduced:
\begin{inlinecode}
for (int b=0; ; b++) {
  try {
    // atomic actions
  } else {
    backOff(b);
    continue;
  }
  break; // success!
}
\end{inlinecode}

\note{How hard do I try to execute the {\tt try} block?}
I non-deterministically choose to execute the body of the {\tt
  atomic} block if and only if it will be observed by all to execute
atomically.  The same linguistic mechanism I introduced for
fault tolerance and backtracking provides atomic regions for
synchronization as well.
\note{Mention optimistic parallelism here?}

\subsubsection{The \texttt{StringBuffer} class}\label{sec:stringbuffer}
The existing \defni{Monitor synchronization}\index{Synchronization!monitor} methodology for Java,
building on such features in progenitors such as Emerald
\cite{BlackHuJuLe86,JulSt91},\index{Emerald}\footnote{See \charef{emerald}.}
implicitly associates an 
lock with each object.
Data races are prevented by
requiring a thread to acquire an
object's lock before touching the object's shared fields.
However, the lack of races is not sufficient to prevent unanticipated
parallel behavior.

Flanagan and Qadeer \cite{FlanaganQa03} demonstrated this
insufficiency with an
actual bug they discovered in the Sun JDK 1.4.2 Java standard
libraries.  The \texttt{java.lang.StringBuffer}\index{java.lang.StringBuffer@\texttt{java.\bp{}lang.\bp{}StringBuffer}} class,
which implements a mutable string abstraction, is implemented as follows:
\begin{inlinecode}
public final class StringBuffer ... {
  private char value[];
  private int count;
  ... 
  public synchronized
  StringBuffer append(StringBuffer sb) {
    ...
A:  int len = sb.length();
    int newcount = count + len; 
    if (newcount > value.length)
      expandCapacity(newcount);
    // next statement may use stale len
B:  sb.getChars(0, len, value, count);
    count = newcount;
    return this;
  }
  public synchronized int length() { return count; }
  public synchronized void getChars(...) { ... }
}
\end{inlinecode}

The library documentation indicates that the methods of this class are meant
to execute atomically, and the {\tt synchronized} modifiers on the
methods are meant to accomplish this.

However, the {\tt append()} method is \emph{not} atomic.  Another
thread may change the length of the parameter \texttt{sb} (by adding
or removing characters) between the call to \texttt{sb.length()} at
label A and the call to \texttt{sb.getChars(\ldots)} at label B.
This non-atomicity may cause incorrect data to be appended to the
target or a \texttt{StringIndexOutOfBoundException} to be thrown. 
Although the calls to
\texttt{sb.length()} and \texttt{sb.getChars()} are individually
atomic, they do not compose to form an atomic implementation of
\texttt{append()}.  
%The simple monitor synchronization scheme breaks
%down when operations touch multiple objects.

Note that replacing {\tt synchronized} with {\tt atomic} in
this code gives us the semantics
we desire: the atomicity of nested {\tt atomic} blocks is guaranteed
by the atomicity of the outermost block, ensuring that the entire
operation appears atomic.

Both the network flow example and this {\tt StringBuffer} example require
synchronization of
changes to more than one object.
Monitor synchronization is not
well-suited to this task.  Atomic regions implemented with
transactions can be used to simplify the locking discipline required
to synchronize multi-object mutation
and provide a more intuitive specification for the desired
concurrent properties.  Further, the {\tt StringBuffer} example shows
that simply replacing {\tt synchronized} with {\tt atomic} provides a
alternative semantics which may in fact correct existing
synchronization errors.
For many Java programs, the
semantics of {\tt atomic} and {\tt synchronized} are identical; see
\charef{semantic}.
\note{Can I make this rigorous?}

\subsection{Some things we still can't (easily) do}\label{sec:xlimit}
The transaction mechanism presented here is not a universal
replacement for all synchronization.  In particular, transactions
cannot replace blocking producer-consumer queues and mutual exclusion
required to serialize I/O, although the needed locks can certainly be
built with transactions.  Integrating I/O within a transactional
context remains poorly understood.  However, large programs---the
Linux kernel\note{TODO: Find citation}, for example---have been
written such that locks are
never held across context switches or I/O operations.  Transactions
provide a complete solution for this limited synchronization.
One of the goals of this thesis is to investigate better integration
of transactional with inherently non-transactional operations.
One promising approach is the addition of explicit ``recovery'' blocks
to undo the effects of non-transactional regions embedded within
an aborting transaction.

\section{Finding transactions}\label{sec:auto}
One of the difficulties of proposing a novel language feature is the
lack of benchmarks for its evaluation.  Although there is no body of
code that uses {\tt atomic} regions, there is a substantial body of
code which uses Java (locking) synchronization.  This thesis will
utilize the Flex compiler \cite{Flex} to
substitute {\tt atomic} blocks (methods) for {\tt
  synchronized} blocks (methods) in order to evaluate the properties
Java transactions are likely to have.  Note that the semantics are not
precisely compatible: the existing \indexed{Java memory model} allows
unsynchronized updates to shared fields to be observed within a
synchronized block, while such updates will never be visible to an
{\tt atomic} block.  The proposed revision of the Java memory model
\cite{MansonPu02} narrows the semantic gap, however I do not
plan to treat {\tt volatile} fields in this work.  See
\charef{semantic} for more details.

Despite the differences in semantics, the automatic substitution of
{\tt atomic} for {\tt synchronized} does, in fact, preserve the
correctness of the benchmarks I have examined.  Moreover, as
mentioned in \charef{stringbuffer}, it
fixes the synchronization issue with {\tt java.lang.StringBuffer}.

One goal of this thesis is to make such improperly synchronized
applications correct and race-free, in effect fixing certain common
synchronization errors.  To this effect, I need to preserve the
correct operation of {\tt atomic} even in the face of unsynchronized
accesses from outside the {\tt atomic} block to the fields used within
it.  Imagine unsynchronized code directly altering the length field of
{\tt StringBuffer}.  This should not cause the {\tt atomic}
{\tt StringBuffer.append()} method to appear non-atomic.
Some existing work on software transaction systems \cite{HarrisFr03}
does not support this style of operation.

\label{sec:properties}
The initial results of this thesis
explore the implications of exposing the transaction
mechanism to user-level code through a compiler.
I compiled the SPECjvm98 benchmark suite with the FLEX Java compiler,
modified to turn synchronized blocks and methods into transactions,
in order to investigate the properties of the transactions in such
``automatically converted'' code.
Method splitting was performed to distinguish methods called from
within an atomic block, and nested
\texttt{atomic} blocks were implemented as a single
transaction around the outermost \texttt{atomic} region.  I
instrumented this transformed program to produce a trace of
memory references and transaction boundaries for analysis.
I found both large
transactions (involving millions of cache lines) and frequent
transactions (up to 45 million of them).

The SPECjvm98 benchmark suite represents a variety of typical Java
applications which use the capabilities of the Java standard library.
Although the SPECjvm98 benchmarks are largely single-threaded, since
they use the thread-safe Java standard libraries they contain
synchronized code which is transformed into transactions.  Because in
this evaluation I am looking at transaction properties only, the
multithreaded \texttt{227\_mtrt} benchmark is identical to its
serialized version, \texttt{205\_raytrace}.  For consistency, I present
only the latter.

\begin{figure}\sis%
\begin{center}
\begin{tabular}{lrrrr}
        & total      &              & transactional & biggest\\
program & memory ops & transactions & memory ops    & transaction \\\hline
{\tt 201\_compress} & 2,981,777,890 & 2,272 & $<$0.1\% & 2,302 \\
{\tt 202\_jess} & 405,153,255 & 4,892,829 & 9.1\% & 7,092 \\
{\tt 205\_raytrace} & 420,005,763 & 4,177 & 1.7\% & 7,149,099 \\
{\tt 209\_db} & 848,082,597 & 45,222,742 & 23.0\% & 498,349 \\
{\tt 213\_javac} & 472,416,129 & 668 & 99.9\% & 118,041,685 \\
{\tt 222\_mpegaudio} & 2,620,818,169 & 2,991 & $<$0.1\% & 2,281 \\
{\tt 228\_jack} & 187,029,744 & 12,017,041 & 34.2\% & 14,266 \\
\end{tabular}
\end{center}
\caption[Transactification of SPECjvm98 benchmark suite.]%
 {Transactification of SPECjvm98 benchmark suite: resulting
  transaction counts and sizes, compared to total number of memory
  operations (loads and stores).  These are full input size runs.
}\label{fig:perfnums}
\end{figure}
\figput{tr-quad}{Classification of SPECjvm98 benchmarks into quadrants
based on transaction properties.}

\figref{perfnums} shows the raw sizes and frequency of transactions in
the transactified SPECjvm98 suite.
\figref{tr-quad} proposes a
taxonomy for Java applications with transactions, grouping the SPECjvm98
applications into quadrants based on the number and size of the
transactions which they perform.  Applications in Quads II and IV
require an efficient transaction implementation, because they contain
many transactional operations.
Quads III and IV contain at least some very large transactions, which
pose difficulties for currently-proposed hardware transactional memory
schemes.  We will now
examine the benchmarks in each quadrant to determine why its program
logic caused it to be classified in that quadrant.

Quad I applications perform few (up to about 2000) small
transactions.  These applications include \texttt{201\_compress}, an
implementation of gzip compression, and \texttt{222\_mpegaudio}, an
MP3 decoder.  Both of these applications perform inherently serial
tasks.  They perform quite well with locks, and would likely execute
with acceptable performance even with a na\"\i{}ve software
implementation of transactions, as long as the impact on
non-transactional operations was minimal.

Quad II applications perform a large number of small transactions.
The expert system \texttt{202\_jess} falls in this category, as do
small input sizes of \texttt{209\_db}, a database.  These benchmarks
perform at least an order of magnitude more transactions than Quad
I applications, and all of the transactions are small enough to 
comfortably fit the known hardware transactional memory schemes
\cite[etc]{HerlihyMo93}, if
one were to be implemented.

Quad III includes \texttt{205\_raytrace}, a ray-tracing renderer.  A
small number of transactions are performed, but they may grow very
large.  Existing bounded hardware transactional schemes will not
suffice.  The large
transactions may account for a large percentage of total memory
operations, which may make software schemes
impractical.

Finally, Quad IV applications such as \texttt{209\_db} and the
\texttt{213\_javac} Java compiler application perform a large number
of transactional memory operations with at least a few large transactions.  

The \texttt{213\_javac} Java compiler application and the large input
size of the \texttt{209\_db} benchmark illustrate that some programs
contain \emph{extremely} large transactions.  When \texttt{213\_javac}
is run on its full input set, it contains 4 very large transactions,
each of which contains over 118 million transactional memory
operations.  Closer
examination reveals that the method \texttt{Javac.compile()}, which
implements the entire compilation process, is marked as synchronized:
the programmer has explicitly requested that the entire compilation
occur atomically.

The large transactions in Quad III and IV may be, as in this case, a result of
overly-coarse--grained locking, but our goal is to
relieve the programmer from the burden of specifying correct
atomic regions of smaller granularity.  Performance may benefit from
narrowing the atomic regions, but execution with coarse regions should
be possible and not prohibitively slow.

The \texttt{209\_db} benchmark suffers from a different problem: at one
point the benchmark atomically scans an index vector and removes an
element, creating a potentially large transaction if the index is
large.  The size of this index is correlated in these benchmarks with
the input size, but it need not be: a large input could still result
in a small index, and (to some degree) vice-versa.

A similar situation arises in the {\tt java.lang.StringBuffer} code
shown in \ref{sec:stringbuffer}:  a call to the synchronized
\texttt{sb.getChars()} method means that
the size of the transaction for this method will grow like the length
of the parameter~\texttt{sb}.  In other words, the transaction can be
made arbitrarily large by increasing the length of \texttt{sb}; or,
equivalently, there is no bound on transaction size without a bound on
the size of the string~\texttt{sb}.

\epsfigput[Distribution of transaction size in the SPECjvm98 benchmark
  suite.]{tr-sz-all}{Distribution of transaction size in the
  SPECjvm98 benchmark suite.  Note that the x-axis uses a logarithmic
  scale.}

Any scheme which allows the programmer free reign over specifying
desired transaction and/or atomicity properties will inevitably result
in some applications in each of these categories.  Existing
hardware transactional memory schemes only efficiently handle
relatively short-lived and small transactions (Quad I or II),
although for these they are very efficient.  Object-based
transaction systems can asymptotically approach that efficiency for
very long-lived transactions;  the existence of such is shown in
\figref{tr-sz-all}, which plots
the distribution of transaction sizes in SPECjvm98
on a semi-log scale.


\vspace*{5mm}

These initial results show that real applications can be
transactified with modest effort, yielding significant gains in
concurrency.  In other work \cite{AnanianAsKuLeLi04} we have shown
that a factor of 4 increase in concurrency can be obtained
by doing nothing more than converting locks to transactions.  Since
the transactified applications may contain large transactions,
proposed hardware support for transactions is inadequate.


\section{Organization of Thesis}
\note{XXX: fix me!}

In the next chapter, I will present an efficient software
implementation of transactions. This may be too slow in some circumstances.

In Chapter XYZ, I will present hardware which enables very fast
transactions.  These may not be capable enough, but the hardware is
easy to build.

In Chapter ABC, I will present extensions to the hardware which allow
more capable transactions.  This may be the wrong approach.

In Chapter DEF, I present an \defn{hybrid} transaction implementation,
which builds on the strengths of simple hardware support, while
allowing software fallback to support a robust and capable transaction
mechanism.

In the following chapter, we discuss some ways compilers can further
optimize software and hybrid transaction systems.  These opportunities
may not be available to pure-hardware implementations.

In the next chapter, we discuss remaining challenges to the use of
ubiquitous transactions for synchronization, and present some ideas
toward solutions.

Chapter ASD discusses related work, and our final chapter summarizes
our findings and draws conclusions.


% LocalWords:  atomicity transactional linearization SMP LTM UTM TCC backoff
