% -*- latex -*- This is a LaTeX document.
% $Id: oopsla02.tex,v 1.4 2002-03-22 05:02:20 cananian Exp $
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[preprint]{acmconf}
% don't forget to turn off 'preprint' before submission!
%\usepackage[section,plain]{algorithm}
%\usepackage{amsthm} % proof environment
%\usepackage{amstext} % the \text command for math mode (replaces \mbox)
\usepackage{varioref} % \vref command
\usepackage{graphicx} % for eps figures
\usepackage{color}
\usepackage{comdef}
\newcommand{\figscale}{1.0}

%setup varioref package
\renewcommand{\reftextbefore}{on the preceding page}\vrefwarning

\newcommand{\mycomment}[1]{}

\title{\bf Data Size Optimizations for Java Programs}

\author{C.~Scott~Ananian and Martin~Rinard\\
        Laboratory for Computer Science\\
        Massachusetts Institute of Technology\\ 
        Cambridge, MA 02139 \\ 
        {\tt \{cananian, rinard\}@lcs.mit.edu} }

\begin{document}
% in preprint mode, tag pages with a revision identifier.
%\pagestyle{myheadings}\markboth{$ $Revision: 1.4 $ $}{$ $Revision: 1.4 $ $}
\bibliographystyle{plain}

\maketitle

% abstract
\begin{abstract}

{\bf\Large FIX ME! }
This paper presents a set of Java optimizations targeted at
memory-constrained embedded devices.  Using the FLEX compiler system,
we aggressively transform
programs using both source-level transformations and
specializations of the runtime environment to save as much
as 54\% of the storage requested by the allocator.

Our techniques fall into three broad categories: header optimizations,
bitwidth analyses, and mostly-zero field elimination.  Header
optimizations reduce the size penalties associated with 
Java's virtual dispatch, hashcode, and locking features.  Bitwidth
analyses allow compile-time reduction of field sizes when the
full range of a datatype is unused.  Mostly-zero field elimination
attempts to factor out fields which are ``usually zero'' (as
determined by profiling) to obtain savings.  Combined, these
techniques allow the compiler to shoulder the burden of space accounting
and allow the use of general-purpose software on extremely
memory-constrained embedded devices.

\end{abstract}

\section{Introduction}

This paper presents a set of techniques for reducing the
amount of data space required to represent objects
in object-oriented programs. Our techniques optimize
the representation of both the programmer-defined fields
within each object and the header information used by the
run-time system:
\begin{itemize}
\item {\bf Field Reduction:} 
Our a flow-sensitive, interprocedural bitwidth analysis
analysis computes the range of values that the program
may assign to each field. The compiler then transforms the program
to reduce the size of the field to the smallest size 
capable of storing that range of values. 
\item {\bf Constant Field Elimination:} 
If the bitwidth analysis finds that field always holds
the same constant value, the compiler eliminates the field. 
It removes each write to the field, and replaces each read
with the constant value.
\item {\bf Static Specialization:} Our analysis finds 
classes with fields whose values do not change after initialization,
even though objects allocated at different allocation sites may
have different values for these fields. It then generates 
a specialized version of each class for each allocation site;
this version omits the fields and instead provides accessor
methods that return the corresponding values. 
\item {\bf Field Externalization:} Our analysis uses profiling
to find fields that almost always have the same default value. 
It then removes these fields from their enclosing class, 
using a hash table to store values of the field that differ
from the default value. It replaces writes to the field with
an insertion into the hash table (if the written value is not the
default value) or a removal from the hash table (if the written value
is the default value). It replaces reads with hash table lookups; 
if the object is not present in the hash table, the lookup simply
returns the default value. 
\item {\bf Unused Field Analysis:} If the program does not
use a field, the compiler eliminates the field. 
\item {\bf Claz Compression:} Our class hierarchy analysis
computes an upper bound on the number of classes that the
program may instantiate. Objects in standard 
Java implementations have a header that contains a pointer
to the class data (such as the method dispatch table) for that object. 
Our compiler uses the results of the class
hierarchy analysis to replace the reference with a smaller
offset into a table of pointers to the class data. 
\item {\bf Byte Packing:} All of the above transformations may
reduce or eliminate the amount of space required to store each
field in the object or object header. Our byte packing algorithm
arranges the fields in the object to minimize the amount of 
storage. 
\end{itemize}
All of these transformations reduce the space required to store
objects, but potentially increase the running time of the program.
Our experimental results show that, for our set of benchmark
programs, all of our combined techniques can reduce the peak amount of memory
required to run the program by as much as XXX\% and never reduce the
running time by more than YYY\%.

\subsection{Contributions}

This paper makes the following contributions:
\begin{itemize}
\item {\bf Space Reduction Transformations:} It presents a set
of novel transformations for reducing the memory required to 
represent objects in object-oriented programs.

\item {\bf Analysis Algorithms:} It presents a set of 
analysis algorithms that automatically extract the 
information required to apply the space reduction 
transformations.

\item {\bf Implementation:} We have fully 
implemented all of the analyses and techniques 
presented in the paper. Our experience with this
implementation enables us to discuss the pragmatic
details of developing an effective implementation 
of our techniques. 

\item {\bf Experimental Results:} It presents a set
of experimental results that characterize the impact
of our transformations. 
\end{itemize}

\section{Example}

We next present several examples that illustrate the kinds of 
analyses and transformations that our compiler performs.

\subsection{Field Reduction and Constant Field Elimination}

Figure~\ref{fig:value} presents the {\tt Value} class, which is 
a wrapper around either an {\tt Integer} object or a {\tt Float}
object. The {\tt type} field indicates which kind of object
is stored in the {\tt value} field of the class, 
which essentially implements a tagged 
union.\footnote{This class is a simplfied version of similar
classes that appear in some of our benchmarks.} 
The class also maintains the {\tt positive} field, which is
{\tt 1} if the wrapped number is positive and {\tt 0} otherwise. 

Our bitwidth analysis uses an interprocedural
value-flow algorithm to compute upper and lower bounds for the
values that can appear in each variable. This analysis tracks
the flow of values across procedure boundaries via parameters,
into and out of the heap via instance variables of classes, and through
intermediate temporaries and local variables in the program.
It also reasons about the semantics of arithmetic operators such
as {\tt +} and {\tt *} to obtain bounds for the values computed
by arithmetic expressions. 
This analysis discovers the following facts about 
how the program uses this class: 1) the {\tt integerType} 
field always has the value {\tt 0}, 2) the {\tt floatType} 
field always has the value {\tt 1}, 3) the {\tt type} 
field always has a value between {\tt 0} and {\tt 1} (inclusive),
and 4) the {\tt positive} field always has a value between 
{\tt 0} and {\tt 1} (also inclusive).

\begin{figure}
\begin{verbatim}
public class Value { 
  int integerType = 0;
  int floatType = 1;
  int type;
  int positive;
  Object value;
  void setInteger(Integer i) { 
    type = integerType;
    value = i;
    if (i.intValue() > 0) positive = 0;
    else positive = 1;
  }
  void setFloat(Float f) { 
    type = floatType;
    value = f;
    if (f.floatValue() > 0.0) positive = 0;
    else positive = 1;
  }
  void setValue(int t, int p, Object v) { 
    type = t;
    positive = p;
    value = v;
  }
}

public class main { 
  public static void main() { 
    Value v = new Value();
    Integer i = new Integer(5);
    v.setValue(v.integerType, 1, i);
  }
}
\end{verbatim}
\caption{\label{fig:value} Value Class}
\end{figure}

Our compiler uses this information to remove all occurrences
of the {\tt integerType} and {\tt floatType} fields from the
program. It replaces each read of the {\tt integerType} field
with the constant {\tt 0}, and each read of the {\tt floatType}
field with the constant {\tt 1}. It also uses the bounds on the 
values of the {\tt type} and {\tt positive} variables to reduce the size of the 
corresponding fields. Our currently implemented compiler rounds
field sizes to the nearest byte required to hold the range
of values that can occur. Our byte packing algorithm then 
generates a dense packing of the values, attempting to preserve
the alignment of the variables if possible. In this case, the
algorithm can reduce the field sizes by six bytes and the overall
size of the object by one four-byte word. 

\subsection{Static Specialization} 

Figure~\ref{fig:string} presents portions of the implementation
of the Java {\tt String} class. The {\tt value} field in this
class refers to a character array that holds the characters
in the string; the {\tt count} field holds the length of the
string. In some cases, instances of the {\tt String} class
are derived substrings of other instances 
(see the {\tt substring} method in Figure~\ref{}), in which case the
{\tt offset} field provides the offset of the starting 
point of the string within the {\vv value} character array. 
Note that the {\tt value}, {\tt offset}, and {\tt count} 
fields are all initialized when the string is constructed
and do not change during the lifetime of the string.

\begin{figure}
\begin{samplecode}
public final class String \{\\
\>private final char value[];\\
\>private final int offset;\\
\>private final int count;\\
\>\ldots\\
\>public char charAt(int i) \{\\
\>\>return value[offset+i];\\
\>\}\\
\>public String substring(int start) \{\\
\>\>int noff = offset + start;\\
\>\>int ncnt = count - start;\\
\>\>return new String(value, noff, ncnt);\\
\>\}\\
\}\\
\end{samplecode}
\caption{Portions of the {\tt java.lang.String} class.}
\label{fig:string-fields}
\end{figure}

In practice, most strings are not substrings of other strings. 
The {\tt offset} field in most strings is therefore {\tt 0}.
Moreover, it is possible to tell at the object creation site
whether the {\tt offset} will be {\tt 0} or some other number.
In fact, all of the public {\tt String} constructors create
strings with {\tt offset} 0; only the {\tt substring} method
creates strings with a non-zero offset. And even at 
calls to the private {\tt String(char [], int, int)} constructor
inside the {\vv substring} method, it is possible to dynamically
test the values of the parameters to determine if the newly
constructed string will have a zero or non-zero offset.

\begin{figure}
\begin{samplecode}
public final class SmallString \{\\
\>private final char value[];\\
\>private final int count;\\
\>int getOffset() \{ return 0; \}\\
\>\ldots\\
\>public char charAt(int i) \{\\
\>\>return value[getOffset()+i];\\
\>\}\\
\}\\
public final class String\\
\>\>extends SmallString \{\\
\>private final int offset;\\
\>int getOffset() \{ return offset; \}\\
\}\\
\end{samplecode}
\caption{Static specialization of {\tt java.lang.String}.}
\label{fig:big-small}
\end{figure}

\begin{figure}
\begin{samplecode}
public SmallString substring(int start) \{\\
\>int noff = offset + start;\\
\>int ncnt = count - start;\\
\>if (noff==0)\\
\>\>return new SmallString(value, noff, ncnt);\\
\>else\\
\>\>return new String(value, noff, ncnt);\\
\}\\
\end{samplecode}
\caption{Dynamic selection among specialized classes in a method
  from {\tt java.lang.String}.}
\label{fig:dyn-select}
\end{figure}

\subsection{Required Analysis Information}


\section{Analysis Algorithms}

\section{Extensions} % ???
% header optimizations.
% pointer compression?

\section{Experimental Results}
\begin{figure}
\includegraphics[scale=0.32,clip=true]{Figures/spaceopt.eps}
\caption{Cumulative reduction in dynamic allocation achieved with
  our transformations.}
\label{fig:total}
\end{figure}
%\begin{figure*}
%\includegraphics[scale=0.65]{Figures/spaceopt-bit.eps}
%\caption{results w/ bit alignment}
%\end{figure*}
\begin{figure}
\includegraphics[scale=0.32,clip=true]{Figures/spec-space.eps}
\caption{Total allocation in spec benchmarks}
\label{fig:space}
\end{figure}

\section{Related work}

%%%% XXXXXXXX FIX ME XXXXXXXXXXXX %%%%%%%%%%%%

Bitwidth analysis of high-level languages is still a fairly new
technique.  To date, the focus has been on
reducing the width of variables to enable the use of limited-bitwidth
operators (such as the MMX instruction set provides)
or removing unnecessary bits from a datapath for
hardware synthesis \cite{stephenson00,ananian:siliconc}.

Similarly, the implementation focus for locking primitives has been to
reduce their size \cite{bacon98} (although they are still present in
every object) or eliminate the synchronization code
\cite{salcianu01} (without removing the lock field from the object).
In this work we attempt to completely remove the fields from the
header, and since locks often share space with other
header information (hashcodes, in the common case), our analysis and
implementation is quite different.  I do not believe there has been
any prior study of the utilization of the system hashcode features.

Sweeny and Tip \cite{SweeneyTip98DeadDataMembers} did a study of dead
members of C++ programs which parallels the unread field
elimination done by our bitwidth analysis.  However, they
fail to identify {\it constant} members, which our SCC-based algorithm
does easily.  Further, our results show that unread and constant field
elimination is very dependent on the coding style of a particular
application.  The collection of techniques we have presented here
gives much more consistent savings over a wide range of benchmarks.

Aggarwal and Randall \cite{aggarwal01} described a array bounds check
removal method using {\it related fields}.  This work attempted to
discover fields, such as {\tt Vector.size}, which are guaranteed to be
less than or equal to the length of some array, for example, the
backing array stored in {\tt Vector.data}.  Tests against the related
field could then provide information about bounds checks on accesses
to the array.  A similar technique could be used in this work to
extend the utility of bitwidth information discovered on related fields.


\section{Conclusions}

\bibliography{harpoon}

%\appendix
%\input{pldi02-appendix}
\end{document}
