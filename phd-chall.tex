% 'Challenges' chapter.
In this section we will review objections that have been raised to
straightforward or na{\"\i}ve transaction implementations.
Some of these objections do not apply to our implementation;
discussion of these may further illuminate our design choices.
Others apply to certain situations, and should be kept in mind when
creating applications.  Some of the problems raised remain unsolved,
and are the subject of future work; for these we will attempt to sketch
research directions.

\section{Performance isolation}\index{Performance isolation}
Zilles and Flint~\cite{ZillesFl05} identified
\defn{performance isolation} as a potential issue for
transaction implementations.  In a system with performance isolation,
the execution of one task (process, thread, transaction) should
complete in an amount of time which is independent of the execution of
other tasks (processes, threads, transactions) in the system.  For
a system with N processors, it is ideal if a task is guaranteed to
complete at least as quickly as it would running alone on 1
processor.

It is obvious that most common systems do not provide any guarantee of
performance isolation: on a typical multi-user system, the execution
of a given task can be made arbitrarily slow by the concurrent
execution of competing tasks.\footnote{Grunwald and
  Ghiasi~\cite{GrunwaldGh02} call this a ``microarchitectural denial
  of service'' attack.}
However, a nontransactional system can
be constructed with a good deal of performance isolation by
appropriately restricting the processes that can be run and the
resources they consume.

Zilles and Flint object that many transactional systems are
constructed such that a single large transaction may monopolize the
atomicity resources such that no other transactions may commit.  By
opening a transaction, touching a large number of memory locations,
and then never closing the transaction, a malicious application may
deny service to all concurrent applications in a transaction system.

For this reason, it is important that there are no global resources
required to complete a transaction.  Our UTM hardware implementation
achieves this end, but the LTM design uses a per-processor overflow
table.  If an LTM design is implemented with a snoopy bus for
coherence traffic, overflows on one processor can impact the
performance of all other processors on the bus.  A directory-based
coherence protocol (as we have described in this thesis) eliminates
this problem.  Hybrid schemes based on LTM also eliminate the problem,
because an overflowing transaction can be aborted and retried in
software, which requires no global resources.

Concerns about performance isolation are not limited to transaction
systems.  Transaction systems provide a solution not available to
systems with lock-based concurrency, however: the offending
transaction can be safely aborted at any point to allow the other
transactions to progress.

\section{Progress guarantees}\label{sec:progress}
\index{Transaction(s)!progress guarantees}
Aborting troublesome transactions raises another potential pitfall:
how do we guarantee that our system will make forward progress?
Zilles and Flint~\cite{ZillesFl05} note that transaction systems are
subject to an ``all-or-nothing'' problem: it's fine to abort a
troublesome large transaction to allow other work to complete, but
then we throw away any progress in that transaction.  The operating
system is forced to either allocate a large transaction all the
resources it requires, or to refuse to make any progress on the
transaction; there is no middle ground.

This criticism applies to the LTM hardware scheme and other
unvirtualized transaction implementation.  In an LTM system, it is the
programmer's responsibility to structure transactions such that the
application is likely to complete.  The operating system will deny
progress when necessary to prevent priority inversion.

The UTM, hybrid, and software-only implementations do not suffer the
same problem.  UTM and software-only implementations can virtualize
the transaction, as all transaction state is in memory.  This allows
the resources required to be paged in incrementally as
needed.  The hybrid scheme, even when built on an unvirtualized
mechanism such as LTM, can abort and fail-over to a virtualized
software system if sufficient resources are not available.

\section{The semantic gap}\label{sec:semantic}
\index{Transaction(s)!semantic gap with locks}
In a vein of optimism, transactions are often casually said to be
``compatible'' with locks: transform your lock acquisition and release
statements to begin-transaction and end-transaction, respectively, and
your application is transformed.  We might even claim that your
application will suddenly be faster/more parallel and that some
lingering locking bugs and race conditions will be cured by the change
as well.

It is the latter part of the claim that draws first scrutiny: if
you've ``fixed'' my race conditions, haven't you altered the semantics
of my program?  What other behaviors might have changed?

Blundell, Lewis, and Martin~\cite{BlundellLeMa05} describe the
``semantic gap'' opened between the locking and
na{\"\i}vely-transactified code.  They point out that programs with
data races -- even ``benign'' ones -- may deadlock when converted to
use transactions, since the data race will never occur.  One may even
wrap every access with a location-specific lock to ``remove'' the race
(for some definitions) without altering the behavior of the locking
code or the deadlock for the transactional version.

This concern is valid, and claims of automatic transactification
should not be taken too lightly.  However, most ``best-practices''
concurrent code \emph{will} behave as expected, and (unlike
timing-dependent code with races) deadlocks make it very obvious where
things go wrong.  Further, type systems are capable of detecting the
deadlocks in transactified code\note{Need citation here.} and alerting
the programmer of the problem.

Blundell, Lewis, and Martin also point out that some transaction
implementations ignore ``non-transactional'' accesses -- even if these
are to locations which are currently involved in a transaction.  This
leads to additional alterations in the semantics of the code.  In the
implementations described in this thesis, we are careful to ensure
that ``non-transactional'' code still executes as if each statement
was its own individual transaction, what Blundell, Lewis, and Martin
term \defn{strong atomicity}.\index{Strong atomicity}\index{Atomicity!strong}

\section{I/O}\index{Transaction(s)!I/O, issues with|(}
To be useful, computing systems must be connected to the outside world
in some fashion.  This creates a discontinuity in the transactional model:
real world events can not be rolled back in the same way as can changes
to program state.

\subsection{Forbidding I/O}
The most straight-forward means to accommodate I/O in the
transactional framework is to forbid it: I/O may only happen outside
of a transaction.  A runtime check or simple type system may be used
to enforce this restriction.

A useful programmer technique in this model is to create a separate concurrent
thread for I/O.  A transaction can interact with a queue to request
I/O, and the I/O thread will dequeue requests and enqueue responses.
This works best for unidirectional communication.  Note that
round-trip communication with the I/O thread can not be accomplished
within a single transaction (deadlock will result), so transactions
still must be broken between a request and reply: some forms of
interaction can not be accomplished atomically.

\subsection{Mutual exclusion}
Another alternative is to integrate mutual exclusion into the
transaction model: once we start an I/O activity within a transaction,
the transaction becomes \defn{uninterruptible}: it may no longer be
aborted, and must be successfully executed through commit.
\index{Transaction(s)!uninterruptible}
Only a single uninterruptible transaction may execute at a given time
(although other interruptible transactions may be concurrent).
Effectively there is a single global mutual exclusion lock for I/O
activity; transactions attempting I/O while the lock is already held
are either delayed or aborted.

This scheme is reasonable as long as I/O is infrequent in
transactions, and is convenient for the programmer.
A single debugging print-statement, however, is sufficient to
serialize a transaction, and efforts to make the single global I/O
lock more fine-grained may ultimately give back the gains in
simplicity and concurrency afforded by transactions in the first place.

\subsection{Postponing I/O}
A hybrid approach attempts to anticipate or postpone I/O operations so
that they run only at transaction start or end.
Only the I/O operations then need to be run serially; the remainder of
the transaction may still execute concurrently.  Input must be moved
to the start of a transaction, and once the input has been consumed,
that transaction must still run uninterruptibly; it may be aborted
only if a push-back buffer can be constructed for the input, which is
not always reasonable.  Output is moved to the end of the transaction,
but only the actual I/O must be performed uninterruptibly: the
transaction can still be aborted at any time prior to commit.

If output and input need to be interleaved, or the input occurs after
an output and thus can not be moved to the start of the transaction,
uninterruptible transactions are still required.  This approach thus
works around the disadvantages of mutual exclusion in some cases, but
a single misplaced debugging statement can still force serialization.

It is worth noting that modern interface hardware is often designed
such that it works well with this approach.  For example, a 3d
graphics or network card will take commands from or deliver input to a
buffer; a single operation is sufficient to hand over a buffer to
the card to commence I/O.  This single I/O action may be made atomic
with the transaction commit.

\subsection{Integrating do/undo}
The most sophisticated integration of I/O with transactions allows the
programmer to specify ``undo'' code for I/O which can not otherwise be
rolled back.  In the database community, these are referred to as
\defn{compensating transactions}.\index{Transaction(s)!compensating}

Again, I/O would be forbidden within ``pure'' transactions; however,
do/undo blocks may be nested within transactions.  A \texttt{do} block
executes uninterruptibly.  If a transaction aborts before it reaches a
\texttt{do} block, rollback occurs conventionally.  If it aborts after it
has executed a \texttt{do} block, then the \texttt{undo} block is
executed uninterruptibly as part of transactional rollback.  Note that
mutual exclusion must still be used in portions of the transaction
processing; ideally the critical regions are short and infrequently
invoked.

The do/undo behavior allows sophisticated exception processing: an
\texttt{undo} block may emit a backspace to the terminal after
\texttt{do} emits a character, or it may send an apology email after
an email is sent irrevocably in a \texttt{do} block.  The do/undo is
invisible to clients outside the transaction.  Sophisticated
libraries can be built up using this mechanism.  For example, disk i/o
may be made transactional using file versioning and journalling.

The \texttt{undo} blocks may be difficult to program.  The most
straightforward implementation would prevent the \texttt{undo} from
accessing any transactional state, and the programmer must take
special care if she is to maintain a consistent view of program state.
A friendlier implementation would present a view of program state such
that it appears that the \texttt{undo} block executes immediately
after the \texttt{do} block, in the same lexical environment
(regardless of what ultimately-aborted transactional code has executed
in the interim).  The programmer is then able to naturally write code
such as the following:
\begin{inlinecode}
String from = ..., to = ..., subject = ...;
do {
  sendEmail(from, to, subject);
} undo {
  sendApology(from, to, "Re: "+subject);
}
/* code here can modify from, to, subject */
/* before transaction commit */
\end{inlinecode}

Presenting a time-warped view to the \texttt{undo} block can be
difficult or impossible, depending on the history mechanism involved.
In particular, if the \texttt{undo} reads a new location, previously
untouched by the transaction, the value of this location at the
(previous) time immediately following the \texttt{do} might be
unavailable.  Presenting an inconsistent view of memory may be
undesirable.

\index{Transaction(s)!I/O, issues with|)}
\section{OS interactions}
\index{Transaction(s)!operating system interactions with}
\index{Operating system(s)!interactions with transactions}
While transaction-style synchronization has been successfully used to
structure interactions within an operating system~\cite{MassalinPu91},
transactions crossing the boundary between operating system and
application present additional challenges.  Some operating system
requests are either I/O operations or can be handled with the same
mechanism used to handle I/O within transactions, as discussed in the
previous section.  Using memory allocation as an example of an OS
request, transactions can be forbidden to allocate memory, required to
take a lock, forced to preallocate all required memory,\footnote{A
retry mechanism can be used to incrementally increase the
preallocation until the transaction can successfully complete.}, or
use a compensation mechanism to deallocate requested memory in case of
abort.

Since the role of an operating system is to adminster shared
resources, special care must be taken that transactions involving
operating system requests do not ``contaminate'' other processes.
In particular, if data in kernel space is to be included in a
transaction:
\begin{itemize}
\item If mutual exclusion may used to implement any part of the
transaction semantics (as in the various I/O schemes above), then it
may be possible to tie up the entire system (including unrelated
processes) until a transaction touching kernel structures commits.
\item If transaction state if to be tracked in the cache, the
kernel address space must be reserved from the application memory map
 on architectures with virtually-addressed caches.
\item It may be desirable to include some loophole mechanism
 so that kernel data structures may be released from the transaction.
 Similarly, the operating system may wish to use transactions within
 itself; it may be desirable for these transactions to be independent
 from the application's invoking transaction.  Motivating examples
 include fault handlers and the paging mechanism, which ought to be
 transparent to the application's transaction.  Section~\ref{sec:nit}
 discusses possible mechanisms.
\end{itemize}

It is possible to handle these challenges simply, for example by
forbidding OS calls within a transaction and aborting transactions if
necessary on context switches or faults.  Such an approach raises
hurdles for the application programmer but simplifies the operating
system's task considerably.  In unvirtualized transaction
implementations such as LTM, this approach also limits the maximum
duration of a transaction to a single time slice, although the OS may
be able to stretch a processes time slice when necessary.

A more sophisticated approach with explicit OS management of
transactions may be able to provide better transparency of
OS/transaction interactions for the application programmer and
improved performance.

\section{Recommendations for future work}
Based on the discussion in this section, a virtualizable transaction
mechanism is recommended: if LTM is implemented in hardware, a hybrid
scheme should support it in order to provide performance isolation and
progress guarantees.  A do/undo mechanism for transactions allows
better management of critical regions where mutual exclusion must be
integrated with the transaction mechanism to support I/O and certain
OS interactions.  All OS interactions can then be performed in
\texttt{do} block so that mutual exclusion need not be extended across
the OS boundary.

% LocalWords:  interruptible uninterruptible uninterruptibly transactification
% LocalWords:  LTM UTM
