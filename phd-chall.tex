% 'Challenges' chapter.
In this section we will review objections that have been raised to
straightforward or na{\"\i}ve transaction implementations.
Some of these objections do not apply to our implementation;
discussion of these may further illuminate our design choices.
Others apply to certain situations, and should be kept in mind when
creating applications.  Some of the problems raised remain unsolved,
and are the subject of future work; for these we will attempt to sketch
research directions.

\section{Performance isolation}
Zilles and Flint~\cite{ZillesFl05} identified
\defn{\indexed{performance isolation}} as a potential issue for
transaction implementations.  In a system with performance isolation,
the execution of one task (process, thread, transaction) should
complete in an amount of time which is independent of the execution of
other tasks (processes, threads, transactions) in the system.  For
a system with N processors, it is ideal if a task is guaranteed to
complete at least as quickly as it would running alone on 1
processor.

It is obvious that most common systems do not provide any guarantee of
performance isolation: on a typical multi-user system, the execution
of a given task can be made arbitrarily slow by the concurrent
execution of competing tasks.\footnote{Grunwald and
  Ghiasi~\cite{GrunwaldGh02} call this a ``microarchitectural denial
  of service'' attack.}
However, a nontransactional system can
be constructed with a good deal of performance isolation by
appropriately restricting the processes that can be run and the
resources they consume.

Zilles and Flint object that many transactional systems are
constructed such that a single large transaction may monopolize the
atomicity resources such that no other transactions may commit.  By
opening a transaction, touching a large number of memory locations,
and then never closing the transaction, a malicious application may
deny service to all concurrent applications in a transaction system.

For this reason, it is important that there are no global resources
required to complete a transaction.  Our UTM hardware implementation
achieves this end, but the LTM design uses a per-processor overflow
table.  If an LTM design is implemented with a snoopy bus for
coherence traffic, overflows on one processor can impact the
performance of all other processors on the bus.  A directory-based
coherence protocol (as we have described in this thesis) eliminates
this problem.  Hybrid schemes based on LTM also eliminate the problem,
because an overflowing transaction can be aborted and retried in
software, which requires no global resources.

Concerns about performance isolation are not limited to transaction
systems.  Transaction systems provide a solution not available to
systems with lock-based concurrency, however: the offending
transaction can be safely aborted at any point to allow the other
transactions to progress.

\section{Progress guarantees}\label{sec:progress}\index{progress guarantees}
Aborting troublesome transactions raises another potential pitfall:
how do we guarantee that our system will make forward progress?
Zilles and Flint~\cite{ZillesFl05} note that transaction systems are
subject to an ``all-or-nothing'' problem: it's fine to abort a
troublesome large transaction to allow other work to complete, but
then we throw away any progress in that transaction.  The operating
system is forced to either allocate a large transaction all the
resources it requires, or to refuse to make any progress on the
transaction; there is no middle ground.

This criticism applies to the LTM hardware scheme.  In an LTM system, it is the
programmer's responsibility to structure transactions such that the
application is likely to complete.  The operating system will deny
progress when necessary to prevent priority inversion.

The UTM, hybrid, and software-only implementations do not suffer the
same problem.  UTM and software-only implementations can represent all
transaction state in memory, which can be paged in incrementally as
needed.  The hybrid scheme can abort and fail-over to software if
sufficient resources are not available.

\section{The semantic gap}\label{sec:semantic}\index{semantic gap}
In a vein of optimism, transactions are often casually said to be
``compatible'' with locks: transform your lock acquisition and release
statements to begin-transaction and end-transaction, respectively, and
your application is transformed.  We might even claim that your
application will suddenly be faster/more parallel and that some
lingering locking bugs and race conditions will be cured by the change
as well.

It is the latter part of the claim that draws first scrutiny: if
you've ``fixed'' my race conditions, haven't you altered the semantics
of my program?  What other behaviors might have changed?

Blundell, Lewis, and Martin~\cite{BlundellLeMa05} describe the
``semantic gap'' opened between the locking and
na{\"\i}vely-transactified code.  They point out that programs with
data races -- even ``benign'' ones -- may deadlock when converted to
use transactions, since the data race will never occur.  One may even
wrap every access with a location-specific lock to ``remove'' the race
(for some definitions) without altering the behavior of the locking
code or the deadlock for the transactional version.

This concern is valid, and claims of automatic transactification
should not be taken too lightly.  However, most ``best-practices''
concurrent code \emph{will} behave as expected, and (unlike
timing-dependent code with races) deadlocks make it very obvious where
things go wrong.  Further, type systems are capable of detecting the
deadlocks in transactified code\note{Need citation here.} and alerting
the programmer of the problem.

Blundell, Lewis, and Martin also point out that some transaction
implementations ignore ``non-transactional'' accesses -- even if these
are to locations which are currently involved in a transaction.  This
leads to additional alterations in the semantics of the code.  In the
implementations described in this thesis, we are careful to ensure
that ``non-transactional'' code still executes as if each statement
was its own individual transaction, what Blundell, Lewis, and Martin
term \defn{\indexed{strong atomicitity}}.

\section{I/O}
To be useful, computing systems must be connected to the outside world
in some fashion.  This creates a discontinuity in the transactional model:
real world events can not be rolled back in the same way as changes
to program state.

\subsection{Forbidding I/O}
\subsection{Integrating do/undo}
\subsection{Mutual exclusion}
\subsection{Postponing I/O}

Ways to deal with this:
 * forbid transactions - use type system or etc; programmer must
   explicitly end a transaction in order to do i/o.  Write I/O as
   communications with a concurrent thread.
 * integrate do/undo model.  libraries can be built up,
   i.e. ``transactional disk i/o'' based on journalling.
 * use mutual exclusion: once we start an i/o activity, the
   transaction is uninterruptible.
 * postpone i/o and fire it off (uninterruptibly) when the transaction
   commits.  Modern I/O devices (designed for mulitasking systems)
   typically work something like this: create a command buffer, then
   do a single I/O operation to ``do it''.

\section{OS interactions}
Some parts here are related to I/O issues.  Classify system calls as
``safe'' or not.  But also -- transactions in different processes can
interact with each other through the OS, even things like requesting
additional memory.
